{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from IPython.display import display, Latex\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plane Answers to Complex Questions: The Theory of Linear Models, Fifth Ed., Ronald Christensen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{Y}=\\mathbf{X}\\beta+\\mathbf{e}$$\n",
    "\n",
    "where $\\mathbf{Y}$ is an $n\\times1$ vector of random obesrvations, $\\mathbf{X}$ is an $n\\times p$ matrix of knwon constants called the model (or design) matrix, $\\beta$ is a $p\\times1$ vector of unobservable fixed parameters, and $\\mathbf{e}$ is an $n\\times1$ vector of unobservable random errors. Both $\\mathbf{Y}$ and $\\mathbf{e}$ are random vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearModel:\n",
    "\n",
    "    def __init__(self, \n",
    "                 n: int, \n",
    "                 p: int, \n",
    "                 Y: np.array=None, \n",
    "                 X: np.array=None, \n",
    "                 Beta: np.array=None, \n",
    "                 e: np.array=None\n",
    "                 ):\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.Y = Y\n",
    "        self.X = X\n",
    "        self.Beta = Beta\n",
    "        self.e = e\n",
    "        if self.Y is not None and self.Y.shape != (self.n, 1):\n",
    "            display(Latex(f'$$Y\\\\text{{ must be of shape ({self.n}, 1), not {self.Y.shape}}}$$'))\n",
    "            raise ValueError()\n",
    "        \n",
    "        if self.X is not None and self.X.shape != (self.n, self.p):\n",
    "            display(Latex(f'$$X\\\\text{{ must be of shape }}(n={self.n},p={self.p})\\\\text{{, not }}{self.X.shape}$$'))\n",
    "            raise ValueError()\n",
    "        \n",
    "        if self.Beta is not None and self.Beta.shape != (self.n, 1):\n",
    "            display(Latex(f'$$\\\\beta\\\\text{{ must be of shape ({self.p},1), not {self.Beta.shape}}}$$'))\n",
    "            raise ValueError()\n",
    "        \n",
    "        if self.e is not None and self.e.shape != (self.n, 1):\n",
    "            display(Latex(f'$$e\\\\text{{ must be of shape ({self.n},1), not {self.e.shape}}}$$'))\n",
    "            raise ValueError()\n",
    "        \n",
    "    def display(self):\n",
    "        if self.Y is None:\n",
    "            Y = [[sympy.Symbol(f\"y_{{{i + 1}}}\")] for i in range(self.n)]\n",
    "        else:\n",
    "            Y = self.Y\n",
    "        \n",
    "        if self.X is None:\n",
    "            if self.p > 1:\n",
    "                X = [[sympy.Symbol(f'x_{{{i + 1},{j + 1}}}') for j in range(self.p)] for i in range(self.n)]\n",
    "            else:\n",
    "                X = [[sympy.Symbol(f'x_{{{i + 1}}}')] for i in range(self.n)]\n",
    "        else: \n",
    "            X = self.X\n",
    "\n",
    "        if self.Beta is None:\n",
    "            Beta = [[sympy.Symbol(f'\\\\beta_{{{i + 1}}}')] for i in range(self.p)]\n",
    "        else:\n",
    "            Beta = self.Beta\n",
    "        \n",
    "        if self.e is None:\n",
    "            e = [[sympy.Symbol(f'e_{{{i + 1}}}')] for i in range(self.n)]\n",
    "        else:\n",
    "            e = self.e\n",
    "\n",
    "        Y = sympy.Matrix(Y)._repr_latex_().replace('\\\\displaystyle ', '').replace('$', '')\n",
    "        X = sympy.Matrix(X)._repr_latex_().replace('\\\\displaystyle ', '').replace('$', '')\n",
    "        Beta = sympy.Matrix(Beta)._repr_latex_().replace('\\\\displaystyle ', '').replace('$', '')\n",
    "        e = sympy.Matrix(e)._repr_latex_().replace('\\\\displaystyle ', '').replace('$', '')\n",
    "\n",
    "\n",
    "        display(Latex(f\"$${Y}={X}{Beta}+{e}$$\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Linear models specify the expected value of the observed data $\\mathbf{Y}$ as a linear function of the parameter vector $\\beta$*. To be a *linear model* $\\mathbb{E}(\\mathbf{e})=0$. The *standard linear model* assumes that the errors have a common unknown variance and $Cov(\\mathbf{e})=\\sigma^2\\mathbf{I}$ where $\\sigma^2$ is some unknown parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get tests and confidence regions for a standard linear model, we will assume that the $\\mathbf{e}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^2\\mathbf{I},)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The essence of linear model theory is decompose the observations $\\mathbf{Y}$ into $\\mathbf{Y}=\\hat{\\mathbf{Y}}+\\hat{\\mathbf{e}}$. Here $\\hat{\\mathbf{Y}}$ is a vector of *fitted values* that contains all the information for estimating the unknown parameter vector $\\beta$, where $\\hat{\\mathbf{Y}}\\in C(\\mathbf{X})$. With any good statistical procedure, it is necessary to investigate whether the assumtpions that have been made are reasonable. $\\hat{\\mathbf{e}}$ is a vector of *residuals* that contains the information used for checking the assumptions built into the linear model and for estimating the parameters associated with the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications of linear models often fall into two special cases: *Regresion Analysis* and *Analysis of Variance*. Regression refers to models in which the matrix $\\mathbf{X}'\\mathbf{X}$ is nonsingular. Analysis of Variance (ANOVA) models are models in which the model matrix consists entirely of zeros and ones. ANOVA models are sometimes classification models but in recent years that name has been co-opted for models in which the components of $Y$ are binary.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1.0.1** - Simple Linear Regression\n",
    "\n",
    "Consider the model\n",
    "\n",
    "$$y_i=\\beta_0+\\beta_1x_i+e_i$$\n",
    "\n",
    "for $i=1,\\ldots,6$, $(x_1,x_2,x_3,x_4,x_5,x_6)=(1,2,3,4,5,6)$, where the $e_i\\overset{\\text{i.i.d.}}{\\sim}\\mathcal{N}(0,\\sigma^2)$. In matrix notation we can write this as\n",
    "\n",
    "\n",
    "$$\\begin{bmatrix}y_1\\\\y_2\\\\y_3\\\\y_4\\\\y_5\\\\y_6\\end{bmatrix}=\\begin{bmatrix}1&1\\\\1&2\\\\1&3\\\\1&4\\\\1&5\\\\1&6\\end{bmatrix}\\begin{bmatrix}\\beta_0\\\\\\beta_1\\end{bmatrix}+\\begin{bmatrix}e_1\\\\e_2\\\\e_3\\\\e_4\\\\e_5\\\\e_6\\end{bmatrix}$$\n",
    "$$Y=X\\beta+e$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(LinearModel):\n",
    "    def __init__(self, \n",
    "                 n: int, \n",
    "                 Y: np.array=None, \n",
    "                 X: np.array=None, \n",
    "                 Beta: np.array=None, \n",
    "                 e: np.array=None\n",
    "                 ):\n",
    "        super(SimpleLinearRegression, self).__init__(\n",
    "            n=n,\n",
    "            p=2,\n",
    "            Y=Y,\n",
    "            X=X, \n",
    "            Beta=Beta,\n",
    "            e=e\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}y_{1}\\\\y_{2}\\\\y_{3}\\\\y_{4}\\\\y_{5}\\\\y_{6}\\end{matrix}\\right]=\\left[\\begin{matrix}1.0 & 1.0\\\\1.0 & 2.0\\\\1.0 & 3.0\\\\1.0 & 4.0\\\\1.0 & 5.0\\\\1.0 & 6.0\\end{matrix}\\right]\\left[\\begin{matrix}\\beta_{1}\\\\\\beta_{2}\\end{matrix}\\right]+\\left[\\begin{matrix}e_{1}\\\\e_{2}\\\\e_{3}\\\\e_{4}\\\\e_{5}\\\\e_{6}\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_linear_regression = SimpleLinearRegression(\n",
    "    n=6,\n",
    "    X=np.hstack((np.ones((6, 1)), np.arange(1, 7).reshape(-1, 1)))\n",
    ")\n",
    "\n",
    "simple_linear_regression.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1.0.2** - One-Way Analysis of Variance\n",
    "\n",
    "$$y_{ij}=\\mu+\\alpha_i+e_{ij}$$\n",
    "\n",
    "for $i=1,\\ldots,3$, $j=1,\\ldots,N$ $(N_1,N_2,N_3)=(3,1,2)$, where $e_{ij}\\overset{\\text{i.i.d.}}{\\sim}\\mathcal{N}(0,\\sigma^2)$, which can be written as\n",
    "\n",
    "$$\\begin{bmatrix}y_{11}\\\\y_{12}\\\\y_{13}\\\\y_{21}\\\\y_{31}\\\\y_{32}\\end{bmatrix}=\\begin{bmatrix}1&1&0&0\\\\1&1&0&0\\\\1&1&0&0\\\\1&0&1&0\\\\1&0&0&1\\\\1&0&0&1\\end{bmatrix}\\begin{bmatrix}\\mu\\\\\\alpha_1\\\\\\alpha_2\\\\\\alpha_3\\end{bmatrix}+\\begin{bmatrix}e_{11}\\\\e_{12}\\\\e_{13}\\\\e_{21}\\\\e_{31}\\\\e_{32}\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of useful alternative methods for writing $\\mathbf{Y}=\\mathbf{X}\\beta+\\mathbf{e}$. Write $\\mathbf{X}$ in terms of its columns and its rows as\n",
    "\n",
    "$$\\mathbf{X}_{n\\times p}=\\left[\\mathbf{X}_1,\\ldots,\\mathbf{X}_p\\right]=\\begin{bmatrix}x_1'\\\\\\vdots\\\\x_n'\\end{bmatrix}$$\n",
    "\n",
    "This leads to\n",
    "\n",
    "$$\\mathbf{Y}=\\sum_{i=1}^p\\beta_j\\mathbf{X}_j+\\mathbf{e}$$\n",
    "\n",
    "and also, listing the elements of $\\mathbf{Y}$ and $\\mathbf{e}$ in the obvious way,\n",
    "\n",
    "$$y_i=x_i'\\beta_i+e_i,\\qquad i=1,\\ldots,n$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Appendix A - Vector Spaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition A.1** Let $\\mathcal{M}$ be a set, $x,y,z\\in\\mathcal{M}$ and $\\alpha,\\beta,\\xi$ be scalars. $\\mathcal{M}$ is a *vector space* if\n",
    "\n",
    "1. $\\forall x.\\forall y.\\forall z:(x+y)+z=x+(y+z)$.\n",
    "\n",
    "2. $\\forall x.\\forall y.\\forall z:x+y=y+x$.\n",
    "\n",
    "3. $\\exists y.\\forall x:x+0=x=0+x$ ($y=0$).\n",
    "\n",
    "4. $\\forall x.\\exists y: x+y=0=y+x$ ($y=-x$).\n",
    "\n",
    "5. $\\forall\\alpha.\\forall x.\\forall y:\\alpha(x+y)=\\alpha x+\\alpha y$.\n",
    "\n",
    "6. $\\forall\\alpha.\\forall\\beta.\\forall x:(\\alpha+\\beta)x=\\alpha x+\\beta x$.\n",
    "\n",
    "7. $\\forall\\alpha.\\forall\\beta.\\forall x:(\\alpha\\beta)x=\\alpha(\\beta x)$.\n",
    "\n",
    "8. $\\exists \\xi.\\forall x:\\xi x=x$ ($\\xi=1$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition A.2** Let $\\mathcal{M}$ be a vector space, and let $\\mathcal{N}$ be a set with $\\mathcal{N}\\subset\\mathcal{M}$. $\\mathcal{N}$ is a *subspace* of $\\mathcal{M}$ if $\\mathcal{N}$ is a vector space using the same defintions of vector addition and scalar multiplication as for $\\mathcal{M}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking of vectors in three dimensions as $(x,y,z)^T$. The subpsace consisting of the $z$ axis is\n",
    "\n",
    "$$\\left\\{\\begin{pmatrix}0\\\\0\\\\z\\end{pmatrix}:z\\in\\mathbb{R}\\right\\}$$\n",
    "\n",
    "The subspace consisting of the $x,y$ plane is \n",
    "\n",
    "$$\\left\\{\\begin{pmatrix}x\\\\y\\\\0\\end{pmatrix}:x,y\\in\\mathbb{R}\\right\\}$$\n",
    "\n",
    "The subpsace consisting of the plane that is perpendicular to the line $x=y$ in the $x,y$ plane is\n",
    "\n",
    "$$\\left\\{\\begin{pmatrix}x\\\\-x\\\\z\\end{pmatrix}:x,z\\in\\mathbb{R}\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Appendix D - Multivariate Distributions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $(x_1,\\ldots,x_n)^T$ be a random vector. The joint cumulative distribution function of $(x_1,\\ldots,x_n)^T$ is\n",
    "\n",
    "$$F(u_1,\\ldots,u_n)\\equiv\\text{Pr}\\left[x_1\\le u_1,\\ldots,x_n\\le u_n\\right]$$\n",
    "\n",
    "If $F(u_1,\\ldots,u_n)$ is the cdf of a discrete random variable, we can define a joint probabilty mass function\n",
    "\n",
    "$$f(u_1,\\ldots,u_n)\\equiv\\text{Pr}\\left[x_1=\\mu_1,\\ldots,x_n= u_n\\right]$$\n",
    "\n",
    "If $F(u_1,\\ldots,u_n)$ admits the $n$-th order mixed partial derivative, then we can define a joint probability density function\n",
    "\n",
    "$$f(u_1,\\ldots,u_n)\\equiv\\frac{\\partial^n}{\\partial u_1\\ldots\\partial u_n}F(u_1,\\ldots,u_n)$$\n",
    "\n",
    "The cdf can be recovered from the density as\n",
    "\n",
    "$$F(u_1,\\ldots,u_n)=\\int_{-\\infty}^{u_1}\\ldots\\int_{-\\infty}^{u_n}f(w_1,\\ldots,w_n)dw_1\\ldots dw_n$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
